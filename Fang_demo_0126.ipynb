{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifang-psu/demo/blob/main/Fang_demo_0126.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author: Yi Fang**\n",
        "\n",
        "## **Content:**\n",
        "\n",
        "0. **Deep Learning Framworks**\n",
        "1. **Sentence Transformer Model**\n",
        "  * 1.1 Model script\n",
        "  * 1.2 Test\n",
        "  * 1.3 Discussion\n",
        "2. **Multi-Task Transformer Model**\n",
        "  * 2.1 Model script\n",
        "  * 2.2 Test\n",
        "  * 3.3 Discussion\n",
        "3. **Training**\n",
        "  * 3.1 Training script\n",
        "  * 3.2 Prepare datasets and train the model\n",
        "  * 3.3 Test\n",
        "  * 3.4 Discussion"
      ],
      "metadata": {
        "id": "C7uE-bad9XVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0-1) Deep Learning Frameworks\n",
        "\n",
        "- PyTorch (used for this demo)\n",
        "- TensorFlow/Keras\n",
        "- JAX/Flax\n",
        "- Hugging Face Transformers (used for this demo)\n",
        "\n",
        "#### Why choose PyTorch with Hugging Face Transformers?\n",
        "- Extensive pre-trained models\n",
        "- Active community support\n",
        "- Clean API for transformer architectures\n",
        "- Efficient fine-tuning capabilities"
      ],
      "metadata": {
        "id": "GuaYYP_hp00X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2e5c8a25-e587-405d-b8e3-61e7bef4e3cf",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GIhiei6Bd6ai",
        "outputId": "9edaf091-58ad-495a-9a86-6ba79901cf59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.36.1)\nRequirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (2.0.1+cpu)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.27.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (2022.7.9)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from transformers) (23.2)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch) (2.8.4)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch  # Uncomment this if you need to install\n",
        "# I developed the following code in Databricks (runtime: ML 15.4 https://docs.databricks.com/en/release-notes/runtime/15.4lts-ml.html)\n",
        "# The code also runs well in Colab (runtime Python 3, CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b820d125-4b41-4a4b-bcf2-4793fa8ef900",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "vLXc3fwRd6ak"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2426ef48-4a00-4575-8ae6-dda1732348b0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHlQvWgXd6ak",
        "outputId": "42007d6d-3187-4537-ac48-505dc2c3e247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 1**"
      ],
      "metadata": {
        "id": "OtoPQ87N-_JC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1-1) Sentence Transformer Model"
      ],
      "metadata": {
        "id": "pPCmbc5BngoN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2f4c9e0d-308c-4bc4-9c74-ae72926663b5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "eQVe0fPhd6al"
      },
      "outputs": [],
      "source": [
        "class SentenceTransformerModel(nn.Module):\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        super(SentenceTransformerModel, self).__init__()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.transformer = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        \"\"\"\n",
        "        Apply mean pooling on the last hidden state to get sentence embeddings.\n",
        "        \"\"\"\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "\n",
        "        # Sum the embeddings for each token, then divide by the number of tokens\n",
        "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9) # it is more numerical stable than using torch.mean()\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "\n",
        "    def encode(self, sentences):\n",
        "        \"\"\"\n",
        "        Tokenize and encode sentences to fixed-length embeddings.\n",
        "        \"\"\"\n",
        "        # sentences can be a list of strings or a single string\n",
        "        if isinstance(sentences, str):\n",
        "            sentences = [sentences]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            sentences,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():  # turn off gradients for inference\n",
        "            model_output = self.transformer(\n",
        "                input_ids=encoding['input_ids'],\n",
        "                attention_mask=encoding['attention_mask']\n",
        "            )\n",
        "\n",
        "        sentence_embeddings = self.mean_pooling(model_output, encoding['attention_mask'])\n",
        "        return sentence_embeddings\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Forward pass for training: returns the sentence embeddings.\n",
        "        \"\"\"\n",
        "        model_output = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        return self.mean_pooling(model_output, attention_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ff6d6101-22ec-4a99-ad3e-777d0d4dd9ab",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "D32jmAMGd6al"
      },
      "source": [
        "## (1-2) Test Sentence Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_sentence_transformer(model, sentences):\n",
        "    \"\"\"\n",
        "    Demonstrates how to use a SentenceTransformerModel for encoding sentences into fixed-length embeddings.\n",
        "    \"\"\"\n",
        "    # Encode the sentences to get embeddings\n",
        "    embeddings = model.encode(sentences)\n",
        "\n",
        "    # Print the shape of the resulting embeddings tensor\n",
        "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "    # Show sample embeddings for each sentence\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        print(f\"\\nSentence {i+1}: {sentence}\")\n",
        "        print(f\"Embedding (first 5 dims): {embeddings[i, :5]}\")\n"
      ],
      "metadata": {
        "id": "8CRsnmaOmZjp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Instantiate your SentenceTransformerModel\n",
        "    model = SentenceTransformerModel(model_name='bert-base-uncased')\n",
        "\n",
        "    # Define some sample sentences\n",
        "    sentences = [\n",
        "        \"Hello world!\",\n",
        "        \"I love AI\",\n",
        "        \"Machine learning is fascinating.\",\n",
        "        \"I love programming in Python.\"\n",
        "    ]\n",
        "\n",
        "    # Run the test function\n",
        "    test_sentence_transformer(model, sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "b4a91c92d42a4eb18b340f560f85945b",
            "dd33d1dcf91d495792d8bf6c2abe9a8e",
            "f324edbaa60c4ed2a96f40e85998b57b",
            "b54fd13d273043f9aa8ef58657f13992",
            "e1e991c6f1de440a86a49ef4e8f11763",
            "a6e5e587417d4ba49ba60eb7d4b77519",
            "1e531e89c9354add817aac6a5bcb2b7c",
            "40a3458374cc4998a2ee880a70969a1e",
            "f4523f57bfbd49529086d7d73d07c0d6",
            "9736a1df56a546128188c652637cc195",
            "1c5e5ba6c8f04f0cbbd6a940fed3a195",
            "59815f5f733340d78656ea6a2f02dd2d",
            "ee294420d32548adbd14ee1e3ac8291a",
            "e2dacd37394b4412a6cfa7cddad3ae0c",
            "87dfd7723a8d4e4e82f2a9464422ec0e",
            "6028a2a3443b4fcaa0fb073c22b3fa66",
            "18387d2d6c274acda2ed5e8ba29b76e7",
            "2a9ca2f3774844538d21bd706e4c8ed6",
            "b37b16980b414558b0349649b7c8926d",
            "9a9210b22cca434a9bed8c52fbf3264a",
            "0ca359c971874001833f8622c8e1abf2",
            "66f51e46fb6a43de9ea357f94a63ccef",
            "19aa18aa9d2940e9bed77e8e81c5c3fa",
            "b9f3ec5195654cffb8294dd87aa7bae9",
            "a98146354acf42dba61184c7177d09ef",
            "9214c0ded5cc4f32a129afd02daf2e10",
            "d6cda59162ea4259a717fd1736821968",
            "75ffbbe5a41347a89294143d530cb9a5",
            "15193d052f614bd1bb9877ff86ba65d2",
            "1f3279bfab8e4f71835253f6bb82ddd7",
            "8686a316710b4b59ba5e26ac9992f0a1",
            "1d668c80d1034709a367ffd832618475",
            "2a47cd7af2ae4b289ae2056625d3c7bd",
            "40b1f42dc9574bbc87bae51802d768bd",
            "455500afe4c54d238073f953d57fc6a8",
            "e191f19741ec472786cef82b8db3ee16",
            "4c2e557b40894093be6d1b777deb1cc6",
            "dfe2c9b7e2944758943485ef1e44cce7",
            "50f3e77efb2d4017a447ea12a8b4a68f",
            "a6b25d5d79004dd79e9ae42d0b3f040e",
            "4095583ec7c646289b854e36de933458",
            "74dd83868cab4783aec65ac381509706",
            "cf1a83cfffaa4e6a850ba7efa892737d",
            "2dcd58ed520b4b88982892f587a7dd65",
            "3bcb8a3d4cb04095a4ebc9a1c3047810",
            "c020f1d92fea40c78552ccb9856cac9d",
            "cd85a79a093d4216882ed696d8e2b9d9",
            "7ceaa997a69c4007a783cc0f10e482ce",
            "c345dece3dc9495bb8f3a1d3edcf8924",
            "2c5e10500cd74799917057585da54f9a",
            "6ebaac54ece04f948c11ce8d07c0913c",
            "bff74c73b6d443dd9280d6d6f70557f8",
            "5e99088fc65a4d7f8d447f68cf8a1904",
            "997629f1f66a4825baa850e39d2c309e",
            "f2f2e3ae35584439896df5b4892a4917"
          ]
        },
        "id": "wgmGgW1JmPrw",
        "outputId": "9d1130ac-f04f-4753-d84a-a9d8f6c9f196"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4a91c92d42a4eb18b340f560f85945b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59815f5f733340d78656ea6a2f02dd2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19aa18aa9d2940e9bed77e8e81c5c3fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40b1f42dc9574bbc87bae51802d768bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bcb8a3d4cb04095a4ebc9a1c3047810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: torch.Size([4, 768])\n",
            "\n",
            "Sentence 1: Hello world!\n",
            "Embedding (first 5 dims): tensor([-0.1373, -0.1593,  0.0821, -0.3459, -0.2501])\n",
            "\n",
            "Sentence 2: I love AI\n",
            "Embedding (first 5 dims): tensor([ 0.2247,  0.3316,  0.1592, -0.0284,  0.1185])\n",
            "\n",
            "Sentence 3: Machine learning is fascinating.\n",
            "Embedding (first 5 dims): tensor([ 0.1596,  0.0725, -0.1440,  0.0461,  0.4271])\n",
            "\n",
            "Sentence 4: I love programming in Python.\n",
            "Embedding (first 5 dims): tensor([ 0.2869,  0.4483, -0.2176, -0.2858,  0.0800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3e48a673-78f0-4c5f-986a-7699dd3e2022",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "YbrhBkvVd6am"
      },
      "source": [
        "## (1-3) Discussion\n",
        "\n",
        "#### what architecture choices are made outside of the transformer backbone and why?\n",
        "\n",
        "1. **Used mean pooling**:\n",
        "  * Common pooling strategy\n",
        "    - mean pooling (used for this implementation)\n",
        "    - token pooling [CLS]: often used as a default representation in BERT\n",
        "    - max pooling: might help highlight the most salient features.\n",
        "    - concatenation of last layers or multiple layers\n",
        "  * Why used mean pooling?\n",
        "    - After obtaining the last_hidden_state from the transformer, I apply mean pooling across all tokens. This is how to produce a single sentence embedding from a matrix of token-level embeddings.\n",
        "    - Mean Pooling incorporates all tokens in the sentence rather than relying on just the [CLS] token.\n",
        "    - [CLS] may fit the classification better than mean pooling (check discussion here: https://discuss.huggingface.co/t/common-practice-using-the-hidden-state-associated-with-cls-as-an-input-feature-for-a-classification-task/14003)\n",
        "\n",
        "2. **No Additional Layers**\n",
        "  * No FC layer added here\n",
        "    - It means that the sentence embedding are essentially the direct output of the backbone and mean pooling\n",
        "  * Why keep it simple?\n",
        "    - It should be sufficient for downstream tasks like similarity, sentiment analysis\n",
        "    - Unless a more complex architecture is preferred for a specific goal/task is required. In this case, we can add training layers, a linear or MLP layer is added on top of the pooled representation to improve performance (for simplicity, this task does not add this layer, for the next multi-task model, the layer is added).\n",
        "\n",
        "#### Why `torch.no_grad()` is used?\n",
        "\n",
        "1. **Inference Mode**:\n",
        "  - Freezing: in this demo code, `torgch.no_grad()` in the `encode` method is used for inference. This effectively does not update the transfomer weights. If the model is aimed for training a specific task, we should remove `torch.no_grad()` and allow backpropagation to fine-tune the transformer backbone.\n",
        "2. **In-Method Convenience**:\n",
        "  * Placing torch.no_grad() inside the encode() method guarantees that anyone calling encode(...) won’t accidentally compute gradients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 2**"
      ],
      "metadata": {
        "id": "8ahtkei7-6jY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2-1) Multi-Task Transformer Model\n",
        "- Task 1: Classification (e.g,. three classes)\n",
        "  - Product-related\n",
        "  - Service-related\n",
        "  - General feedback\n",
        "\n",
        "- Task 2: Sentiment Analysis (e.g., three categories)\n",
        "  - Negative (0)\n",
        "  - Neutral (1)\n",
        "  - Positive (2)"
      ],
      "metadata": {
        "id": "eq-IDjNdn1F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "class MultiTaskTransformer(nn.Module):\n",
        "    CLASSIFICATION_LABELS = ['Product', 'Service', 'General']\n",
        "    SENTIMENT_LABELS = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared Transformer\n",
        "        self.transformer = AutoModel.from_pretrained(model_name)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # Decide if running on CPU or GPU\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Model hidden size (often 768 for BERT-base)\n",
        "        hidden_size = self.transformer.config.hidden_size\n",
        "\n",
        "        # Task-specific heads\n",
        "        self.classifier = nn.Linear(hidden_size, len(self.CLASSIFICATION_LABELS)).to(self.device)\n",
        "        self.sentiment_analyzer = nn.Linear(hidden_size, len(self.SENTIMENT_LABELS)).to(self.device)\n",
        "\n",
        "        # CLS pooler for classification (transform CLS hidden state)\n",
        "        self.cls_pooler = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh()\n",
        "        ).to(self.device)\n",
        "\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        \"\"\"Use mean pooling of the last hidden states for sentence-level representations.\"\"\"\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "\n",
        "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
        "\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "    def cls_pooling(self, model_output):\n",
        "        \"\"\"Use [CLS] token and pass it through a small transformation (cls_pooler).\"\"\"\n",
        "        cls_token = model_output.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)\n",
        "        return self.cls_pooler(cls_token)  # (batch_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None, task=None):\n",
        "        # Remove with torch.no_grad()\n",
        "        outputs = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        if task == 'classification':\n",
        "            pooled = self.cls_pooling(outputs)\n",
        "            return self.classifier(pooled)\n",
        "        elif task == 'sentiment':\n",
        "            pooled = self.mean_pooling(outputs, attention_mask)\n",
        "            return self.sentiment_analyzer(pooled)\n",
        "\n",
        "        # Default\n",
        "        return self.mean_pooling(outputs, attention_mask)\n",
        "\n",
        "\n",
        "    def get_classification_label(self, idx):\n",
        "        return self.CLASSIFICATION_LABELS[idx]\n",
        "\n",
        "    def get_sentiment_label(self, idx):\n",
        "        return self.SENTIMENT_LABELS[idx]\n"
      ],
      "metadata": {
        "id": "EqpoZ7Fmkg1c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2-2) Test Multi-Task Transformer Model (before training or fine-tuning)\n"
      ],
      "metadata": {
        "id": "uUxpDELXoEVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multitask_transformer(model, sentences):\n",
        "    \"\"\"\n",
        "    Demonstrates how to use MultiTaskTransformer for:\n",
        "      1) Classification\n",
        "      2) Sentiment Analysis\n",
        "      3) Default mean-pooled embeddings (no task)\n",
        "    Now it also prints per-class probabilities for each task.\n",
        "    \"\"\"\n",
        "    # Move model to the correct device\n",
        "    model.to(model.device)\n",
        "\n",
        "    # Tokenize inputs\n",
        "    encoding = model.tokenizer(\n",
        "        sentences,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    # Send inputs to model device\n",
        "    input_ids = encoding['input_ids'].to(model.device)\n",
        "    attention_mask = encoding['attention_mask'].to(model.device)\n",
        "\n",
        "    # 1) Classification logits\n",
        "    classification_logits = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        task='classification'\n",
        "    )\n",
        "    # Convert logits to probabilities\n",
        "    classification_probs = torch.softmax(classification_logits, dim=1)\n",
        "    classification_preds = torch.argmax(classification_probs, dim=1)\n",
        "\n",
        "    # 2) Sentiment logits\n",
        "    sentiment_logits = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        task='sentiment'\n",
        "    )\n",
        "    sentiment_probs = torch.softmax(sentiment_logits, dim=1)\n",
        "    sentiment_preds = torch.argmax(sentiment_probs, dim=1)\n",
        "\n",
        "    # 3) Default embeddings (no task)\n",
        "    embeddings = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    # Print out results\n",
        "    print(\"=== MultiTaskTransformer Test ===\\n\")\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        print(f\"Sentence: {sentence}\")\n",
        "\n",
        "        # --- Classification ---\n",
        "        print(\"\\nClassification Probabilities:\")\n",
        "        for j, label in enumerate(model.CLASSIFICATION_LABELS):\n",
        "            prob = classification_probs[i, j].item()\n",
        "            print(f\"{label}: {prob:.3f}\")\n",
        "        class_label = model.get_classification_label(int(classification_preds[i]))\n",
        "        print(f\"Predicted Class: {class_label}\")\n",
        "\n",
        "        # --- Sentiment ---\n",
        "        print(\"\\nSentiment Probabilities:\")\n",
        "        for j, label in enumerate(model.SENTIMENT_LABELS):\n",
        "            prob = sentiment_probs[i, j].item()\n",
        "            print(f\"{label}: {prob:.3f}\")\n",
        "        senti_label = model.get_sentiment_label(int(sentiment_preds[i]))\n",
        "        print(f\"Predicted Sentiment: {senti_label}\\n\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(f\"Embeddings shape (no task): {embeddings.shape}\")\n",
        "    print(\"Example embedding row:\", embeddings[0, :5])\n"
      ],
      "metadata": {
        "id": "Juxiq-NCk1dx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Instantiate the multi-task model\n",
        "    model = MultiTaskTransformer(model_name='bert-base-uncased')\n",
        "\n",
        "    # Sample sentences\n",
        "    test_sentences = [\n",
        "        \"The product quality is outstanding!\",  # Product, Positive\n",
        "        \"Your customer service team was very helpful\",  # Service, Positive\n",
        "        \"I have some general feedback to share\",  # General, Neutral\n",
        "        \"This product is completely useless\",  # Product, Negative\n",
        "        \"The service was mediocre at best\"  # Service, Neutral\n",
        "    ]\n",
        "\n",
        "    # Run our test function\n",
        "    test_multitask_transformer(model, test_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV-SUPEQk91l",
        "outputId": "f234883d-deed-4733-dab4-f2e141fa33ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MultiTaskTransformer Test ===\n",
            "\n",
            "Sentence: The product quality is outstanding!\n",
            "\n",
            "Classification Probabilities:\n",
            "Product: 0.424\n",
            "Service: 0.273\n",
            "General: 0.303\n",
            "Predicted Class: Product\n",
            "\n",
            "Sentiment Probabilities:\n",
            "Negative: 0.342\n",
            "Neutral: 0.369\n",
            "Positive: 0.289\n",
            "Predicted Sentiment: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Sentence: Your customer service team was very helpful\n",
            "\n",
            "Classification Probabilities:\n",
            "Product: 0.394\n",
            "Service: 0.289\n",
            "General: 0.317\n",
            "Predicted Class: Product\n",
            "\n",
            "Sentiment Probabilities:\n",
            "Negative: 0.363\n",
            "Neutral: 0.427\n",
            "Positive: 0.210\n",
            "Predicted Sentiment: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Sentence: I have some general feedback to share\n",
            "\n",
            "Classification Probabilities:\n",
            "Product: 0.391\n",
            "Service: 0.294\n",
            "General: 0.315\n",
            "Predicted Class: Product\n",
            "\n",
            "Sentiment Probabilities:\n",
            "Negative: 0.463\n",
            "Neutral: 0.345\n",
            "Positive: 0.192\n",
            "Predicted Sentiment: Negative\n",
            "\n",
            "--------------------------------------------------\n",
            "Sentence: This product is completely useless\n",
            "\n",
            "Classification Probabilities:\n",
            "Product: 0.374\n",
            "Service: 0.299\n",
            "General: 0.327\n",
            "Predicted Class: Product\n",
            "\n",
            "Sentiment Probabilities:\n",
            "Negative: 0.356\n",
            "Neutral: 0.401\n",
            "Positive: 0.242\n",
            "Predicted Sentiment: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Sentence: The service was mediocre at best\n",
            "\n",
            "Classification Probabilities:\n",
            "Product: 0.361\n",
            "Service: 0.309\n",
            "General: 0.330\n",
            "Predicted Class: Product\n",
            "\n",
            "Sentiment Probabilities:\n",
            "Negative: 0.388\n",
            "Neutral: 0.385\n",
            "Positive: 0.227\n",
            "Predicted Sentiment: Negative\n",
            "\n",
            "--------------------------------------------------\n",
            "Embeddings shape (no task): torch.Size([5, 768])\n",
            "Example embedding row: tensor([ 0.0494, -0.1743, -0.0413, -0.0758,  0.2293], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a1b050ed-2db1-4944-96e7-127de686ec4f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "XyABoip-d6ap"
      },
      "source": [
        "\n",
        "## (2-3) Discussion\n",
        "\n",
        "#### What architecture choices are made outside of the transformer backbone and why?\n",
        "\n",
        "1. Task-Specific Heads:\n",
        "\n",
        "  * The model adds two linear layers:\n",
        "  ```\n",
        "  self.classifier for the classification task (e.g., Product/Service/General).\n",
        "  self.sentiment_analyzer for the sentiment task (Negative/Neutral/Positive).\n",
        "  ```\n",
        "  * These layers map the pooled embedding to the respective label spaces.\n",
        "\n",
        "2. Pooling Strategy:\n",
        "\n",
        "  * CLS Pooling (cls_pooling) for classification:\n",
        "    * The [CLS] token is passed through a small MLP (nn.Linear + nn.Tanh) before classification. This is a learned transformation of the [CLS] embedding.\n",
        "    * Why? CLS pooling is a common approach in BERT-like models, where the [CLS] token is often used as a condensed representation of the entire sequence. The additional linear + Tanh adds a small nonlinearity, which can improve classification performance.\n",
        "\n",
        "  * Mean Pooling (mean_pooling) for sentiment:\n",
        "    * The hidden states are averaged across all tokens to generate a single embedding for sentiment analysis.\n",
        "    * Why? Mean pooling is used for sentiment to capture an average representation of all tokens. Some tasks benefit from seeing all tokens’ contributions rather than focusing on the [CLS] embedding alone.\n",
        "\n",
        "\n",
        "\n",
        "  3. Shared BERT backbone\n",
        "    * Both tasks use the same transformer embeddings but have separate output layers, enabling knowledge sharing while maintaining task-specific predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why the results are NOT good at all?!\n",
        "\n",
        "**(1) Untrained task-specific heads**\n",
        "* The BERT backbone has learned general language representations, but it knows nothing about your specific tasks (product vs. service vs. general, negative vs. neutral vs. positive).\n",
        "* The classification and sentiment analysis heads each have randomly initialized weights. Without fine-tuning or training, they are effectively making predictions randomly (although slightly shaped by the hidden states from BERT).\n",
        "\n",
        "**(2) No fine-tuning data**\n",
        "* Pre-trained models (like BERT) learn universal language features (e.g., synonyms, grammar).\n",
        "* To do well on a downstream task (classification, sentiment analysis), we need to show the model labeled examples that link BERT’s general features to your custom labels.\n",
        "\n",
        "**(3) Softmax probabilities on random logits**\n",
        "* Even though you see probabilities like 0.40, 0.35, etc., these are just the results of the softmax function on random logits. They might look slightly better than uniform by chance, but they are still untrained predictions.\n"
      ],
      "metadata": {
        "id": "hzRofPccxG8_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e8368297-13b5-4971-9e1b-ce0ecddac71b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "RrAO1g-od6aq"
      },
      "source": [
        "\n",
        "\n",
        "**(4) In the training section below, used combined loss function during training and here is why:**\n",
        "- Joint optimization - allows the model to learn optimal parameters that work well for both tasks simultaneously\n",
        "- Task balancing - helps prevent one task from dominating the learning process.\n",
        "- Knowledge sharing - enables transfer of relevant information between tasks through the shared BERT backbone\n",
        "- Efficiency - training both tasks together is more computationally efficient than training separate models\n",
        "- The combined loss can be weighted if needed:\n",
        "  ```\n",
        "  loss = alpha * classification_loss + beta * sentiment_loss\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 3**"
      ],
      "metadata": {
        "id": "fjU9Gy1Z_IZI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b598382b-a8e7-41fd-bbf7-20ab4314bbb1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "0UdJySfqd6ar"
      },
      "source": [
        "\n",
        "## (3-1) Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "69c7a98f-b2c3-4ada-aaa0-d2d92ed3f0d2",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Li-Atw6Od6ar"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "import numpy as np\n",
        "\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, texts, classification_labels, sentiment_labels, tokenizer):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
        "        self.classification_labels = torch.tensor(classification_labels)\n",
        "        self.sentiment_labels = torch.tensor(sentiment_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx],\n",
        "            'token_type_ids': self.encodings['token_type_ids'][idx],\n",
        "            'classification_labels': self.classification_labels[idx],\n",
        "            'sentiment_labels': self.sentiment_labels[idx]\n",
        "        }\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.classification_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ea3ca4bb-2b44-44e5-87be-48e16d5bb4b0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "aKiKsBjPd6ar"
      },
      "outputs": [],
      "source": [
        "def train_multitask_model(\n",
        "    model,\n",
        "    train_texts,\n",
        "    classification_labels,\n",
        "    sentiment_labels,\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    learning_rate= 5e-6,  # 2e-5,\n",
        "    freeze_backbone=True,\n",
        "    unfreeze_after=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Train the MultiTaskTransformer model on CPU with a freeze-then-unfreeze approach.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The multi-task model (with classification/sentiment heads).\n",
        "        train_texts (list): List of training sentences.\n",
        "        classification_labels (list[int]): Labels for classification task.\n",
        "        sentiment_labels (list[int]): Labels for sentiment task.\n",
        "        epochs (int): Number of total epochs.\n",
        "        batch_size (int): Batch size for DataLoader.\n",
        "        learning_rate (float): Learning rate for AdamW optimizer.\n",
        "        freeze_backbone (bool): If True, freeze the transformer backbone at first.\n",
        "        unfreeze_after (int or None): After this many epochs, unfreeze the backbone for fine-tuning.\n",
        "                                      If None, keep it frozen throughout training.\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------\n",
        "    # 1) Prepare dataset\n",
        "    # -------------------------\n",
        "    train_dataset = MultiTaskDataset(\n",
        "        train_texts,\n",
        "        classification_labels,\n",
        "        sentiment_labels,\n",
        "        model.tokenizer\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # -------------------------\n",
        "    # 2) Freeze backbone initially\n",
        "    # -------------------------\n",
        "    if freeze_backbone:\n",
        "        for param in model.transformer.parameters():\n",
        "            param.requires_grad = False # Freeze the backbone parameters (no gradient updates)\n",
        "\n",
        "    # -------------------------\n",
        "    # 3) Create optimizer & loss\n",
        "    # -------------------------\n",
        "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate) # Create an optimizer that only includes parameters with requires_grad=True\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()  # Enable training mode (for heads)\n",
        "\n",
        "    # -------------------------\n",
        "    # 4) Training Loop\n",
        "    # -------------------------\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # Optionally unfreeze backbone after a certain epoch\n",
        "        if unfreeze_after is not None and epoch + 1 == unfreeze_after:\n",
        "            print(f\"Unfreezing backbone after epoch {epoch}...\")\n",
        "            for param in model.transformer.parameters():\n",
        "                param.requires_grad = True\n",
        "            optimizer = AdamW(model.parameters(), lr=learning_rate)  # Re-init optimizer\n",
        "\n",
        "        for batch in train_loader:\n",
        "            # Move inputs to CPU (model is on CPU as well)\n",
        "            batch = {k: v.to('cpu') for k, v in batch.items()}\n",
        "\n",
        "            # 1) Zero out old gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 2) Forward pass: classification\n",
        "            classification_logits = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                token_type_ids=batch['token_type_ids'],\n",
        "                task='classification'\n",
        "            )\n",
        "            classification_loss = criterion(classification_logits, batch['classification_labels'])\n",
        "\n",
        "            # 3) Forward pass: sentiment\n",
        "            sentiment_logits = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                token_type_ids=batch['token_type_ids'],\n",
        "                task='sentiment'\n",
        "            )\n",
        "            sentiment_loss = criterion(sentiment_logits, batch['sentiment_labels'])\n",
        "\n",
        "            # 4) Combined loss\n",
        "            loss = classification_loss + sentiment_loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # 5) Backprop & update\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"[Epoch {epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3-2) Load datasets and train the model\n",
        "* 200 sample text and labels are prepared in a txt file (`training_datasets.txt`)\n",
        "  - Text feedback (col 1)\n",
        "  - Classification labels (0=Product, 1=Service, 2=General) (col 2)\n",
        "  - Sentiment labels (0=Negative, 1=Neutral, 2=Positive) (col 3)"
      ],
      "metadata": {
        "id": "abK_QLFyjMhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_training_data(url):\n",
        "    \"\"\"\n",
        "    Load training data from a given URL, expecting the format:\n",
        "    \"<text>,<classification_label>,<sentiment_label>\".\n",
        "\n",
        "    Args:\n",
        "        url (str): URL of the training dataset file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing three lists:\n",
        "            - train_texts (list): List of text samples.\n",
        "            - classification_labels (list): List of classification labels (int).\n",
        "            - sentiment_labels (list): List of sentiment labels (int).\n",
        "    \"\"\"\n",
        "    # Read the file into a DataFrame, specifying no header since the file does not have one\n",
        "    df = pd.read_csv(url, header=None, names=['text', 'classification_label', 'sentiment_label'])\n",
        "\n",
        "    # Extract the data into separate lists\n",
        "    train_texts = df['text'].tolist()\n",
        "    classification_labels = df['classification_label'].astype(int).tolist()\n",
        "    sentiment_labels = df['sentiment_label'].astype(int).tolist()\n",
        "\n",
        "    return train_texts, classification_labels, sentiment_labels"
      ],
      "metadata": {
        "id": "2sTulOMGnoHx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1fbea9aa-196d-40f4-8ab0-93468af8bfb6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIV8EakDd6as",
        "outputId": "6bb83af4-fbd6-4d2c-b283-9ad8658bab0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/10] Average Loss: 2.2130\n",
            "[Epoch 2/10] Average Loss: 2.1949\n",
            "[Epoch 3/10] Average Loss: 2.1732\n",
            "[Epoch 4/10] Average Loss: 2.1649\n",
            "[Epoch 5/10] Average Loss: 2.1475\n",
            "[Epoch 6/10] Average Loss: 2.1322\n",
            "[Epoch 7/10] Average Loss: 2.1134\n",
            "[Epoch 8/10] Average Loss: 2.0936\n",
            "[Epoch 9/10] Average Loss: 2.0855\n",
            "[Epoch 10/10] Average Loss: 2.0644\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    url = \"https://raw.githubusercontent.com/yifang-psu/demo/refs/heads/main/training_datasets.txt\"\n",
        "\n",
        "    # Call the function to load the data\n",
        "    train_texts, classification_labels, sentiment_labels = load_training_data(url)\n",
        "\n",
        "    # Initialize the model\n",
        "    model = MultiTaskTransformer().to('cpu')\n",
        "\n",
        "    # Train the model with freeze + unfreeze strategy\n",
        "    train_multitask_model(\n",
        "        model=model,\n",
        "        train_texts=train_texts,\n",
        "        classification_labels=classification_labels,\n",
        "        sentiment_labels=sentiment_labels,\n",
        "        epochs=10,               # e.g. 10 total epochs\n",
        "        freeze_backbone=True,    # freeze at first\n",
        "        unfreeze_after=None      # not updating backbone for now\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3-3) Test the trained model"
      ],
      "metadata": {
        "id": "IzEs7qEWjoae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c4b6d7bf-3337-4fc1-81a1-4c761dd9599d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "tv0J-gPqd6as"
      },
      "outputs": [],
      "source": [
        "def test_trained_model(model, test_texts):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Tokenize new texts\n",
        "    encoded = model.tokenizer(\n",
        "        test_texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "        return_token_type_ids=True\n",
        "    ).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get predictions\n",
        "        classification_outputs = model(**encoded, task='classification')\n",
        "        sentiment_outputs = model(**encoded, task='sentiment')\n",
        "\n",
        "        # Convert to probabilities\n",
        "        class_probs = torch.softmax(classification_outputs, dim=1)\n",
        "        sent_probs = torch.softmax(sentiment_outputs, dim=1)\n",
        "\n",
        "        # Get predicted labels\n",
        "        class_predictions = [model.get_classification_label(idx) for idx in class_probs.argmax(dim=1).cpu()]\n",
        "        sent_predictions = [model.get_sentiment_label(idx) for idx in sent_probs.argmax(dim=1).cpu()]\n",
        "\n",
        "        return class_predictions, sent_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "19105148-495d-4e1f-8feb-9424777274ee",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8NLvCh7d6as",
        "outputId": "092ebe17-e423-4f8f-da7f-f172e53ac98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text: Your support team was very helpful\n",
            "Predicted Class: Service\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: This new product is fantastic\n",
            "Predicted Class: Product\n",
            "Predicted Sentiment: Neutral\n",
            "\n",
            "Text: The product quality is outstanding!\n",
            "Predicted Class: Product\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: Your customer service team was very helpful\n",
            "Predicted Class: Service\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: I have some general feedback to share\n",
            "Predicted Class: General\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: This product is completely useless\n",
            "Predicted Class: Product\n",
            "Predicted Sentiment: Neutral\n",
            "\n",
            "Text: The service was mediocre at best\n",
            "Predicted Class: Product\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Text: I hate your horrible product\n",
            "Predicted Class: Product\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "test_texts = [\n",
        "    \"Your support team was very helpful\", # Service, Positive\n",
        "    \"This new product is fantastic\", # Product, Positive\n",
        "    \"The product quality is outstanding!\",  # Product, Positive\n",
        "    \"Your customer service team was very helpful\",  # Service, Positive\n",
        "    \"I have some general feedback to share\",  # General, Neutral\n",
        "    \"This product is completely useless\",  # Product, Negative\n",
        "    \"The service was mediocre at best\",  # Service, Neutral\n",
        "    \"I hate your horrible product\" # Product, Negative\n",
        "]\n",
        "\n",
        "class_preds, sent_preds = test_trained_model(model, test_texts)\n",
        "\n",
        "for text, class_pred, sent_pred in zip(test_texts, class_preds, sent_preds):\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Predicted Class: {class_pred}\")\n",
        "    print(f\"Predicted Sentiment: {sent_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3d9bc136-576c-4523-aca5-831a99fdb864",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "gxO7s_QMd6aq"
      },
      "source": [
        "\n",
        "## (3-4) Discussion\n",
        "\n",
        "#### **(1) When would it make sense to freeze the transformer backbone and only train the task-specific layers?**\n",
        "  * Limited Data:\n",
        "    * If few labeled samples for downstream tasks, fully fine-tuning all BERT parameters often leads to overfitting. Freezing the backbone and training only the final layers can help avoid destroying the pre-trained representations with noisy gradients.\n",
        "\n",
        "  * Limited Compute (CPU-bound or small GPU):\n",
        "    * Fine-tuning the entire transformer can be computationally expensive. Freezing the backbone reduces the number of trainable parameters drastically.\n",
        "\n",
        "  * Faster Training:\n",
        "    * Only update the small classification heads, so training is quicker, especially important on CPU (implemented below).\n",
        "\n",
        "  Note the trade-off: You may lose some performance potential, because the backbone does not adapt to your specific domain or tasks. But if your domain is close to general language or your data is very small, freezing can be effective and more efficient.\n",
        "\n",
        "#### **(2) What changes are made to the architecture to support multi-task learning?**\n",
        "  * Multiple Heads:\n",
        "    * Instead of a single classifier, you now have two separate layers (or “heads”)—one for classification (self.classifier) and one for sentiment analysis (self.sentiment_analyzer).\n",
        "\n",
        "  * Conditional Forward Logic:\n",
        "    * In the forward method, you select which head to use based on the task argument ('classification' vs. 'sentiment'). The model shares the same transformer backbone, but branches into different heads depending on the requested task.\n",
        "\n",
        "  * Different Pooling for Different Tasks:\n",
        "    * cls_pooling for classification\n",
        "    * mean_pooling for sentiment\n",
        "    This is a design choice to best handle each task’s nature.\n",
        "\n",
        "#### **(3) When would it make sense to freeze one head while training the other?**\n",
        "  * Task A Already Converged:\n",
        "    * If Task A is performing well and you don’t want to risk degrading that performance, you can freeze its head and continue training only Task B’s head (and optionally the backbone) for additional epochs.\n",
        "  * Task-Specific Priorities:\n",
        "    * In some scenarios, you might want to preserve a stable classifier in production while experimenting with or improving the sentiment head.\n",
        "  * Different Data Readiness:\n",
        "    * If you have new data for Task B but no new data for Task A, you can keep A’s head frozen (so it remains stable) and fine-tune only B’s head.\n",
        "\n",
        "\n",
        "#### **(4) In what situation, would you decide when to implement a multi-task model like the one in this assignment and when it would make more sense to use two completely separate model for each task?**\n",
        "\n",
        "  1. Multi-Task Model:\n",
        "    * Shared Representations:\n",
        "      * If your tasks are related (e.g., sentence-level classification and sentiment, both about user feedback), the backbone can learn features useful for both tasks. This can improve data efficiency and performance, especially if you have limited data for at least one task.\n",
        "\n",
        "    * Deployment Efficiency:\n",
        "      * A single model can output multiple predictions with one forward pass (less overhead than hosting two completely separate models).\n",
        "\n",
        "    * Regularization Benefit:\n",
        "      * Jointly training on multiple tasks often acts as a form of regularization, preventing overfitting on one single task.\n",
        "\n",
        "  2. Two Separate Models:\n",
        "    * Very Different Tasks or Domains:\n",
        "      * If tasks differ drastically (e.g., sentiment on tweets vs. question-answering on legal documents), the synergy of sharing a backbone might be minimal or even detrimental.\n",
        "\n",
        "    * Scalability Concerns:\n",
        "      * If you can afford separate models for each task and one task requires a specialized architecture, a separate model might be simpler to maintain.\n",
        "\n",
        "    * Different Update Schedules:\n",
        "      * If the tasks are maintained by different teams or require different release cycles, separate models might be more practical.\n",
        "\n",
        "    * Inference speed requirements:\n",
        "      * If one task requires a latency significant different from the other.\n",
        "\n",
        "    * Performance requirements per task:\n",
        "      * If one task performance requirement is significant different from the other.\n",
        "\n",
        "\n",
        "#### **(5) when training the multi-task models, assume that Task A (classification) has abundant data, while Task B (sentiment analysis) has limited data. Explain how you would handle this imbalance?**\n",
        "\n",
        "  The following methods can help with this assumed issue:\n",
        "\n",
        "  1. Weighted Loss or Sampling:\n",
        "\n",
        "    * Weighted Loss:\n",
        "      * Assign a higher loss weight to Task B so it is not overshadowed by Task A’s abundant data. E.g., loss = alpha * classification_loss + beta * sentiment_loss, with beta > alpha to emphasize sentiment.\n",
        "\n",
        "    * Weighted Sampler:\n",
        "      * If using a single training loop that picks samples for both tasks, oversample the fewer-task samples or undersample the abundant task to balance how often each task is trained.\n",
        "\n",
        "  2. Curriculum or Two-Phase Training:\n",
        "    * Phase 1: Train the shared backbone + classification head on abundant classification data (or freeze the backbone if it’s already well-trained).\n",
        "\n",
        "    * Phase 2: Fine-tune on the limited sentiment data with a relatively higher focus (unfreeze the backbone if needed). This ensures the backbone can also adapt to sentiment signals.\n",
        "\n",
        "  3. Data Augmentation (for the smaller task):\n",
        "    * If feasible, artificially augment the sentiment data: paraphrasing negative/positive statements, synonyms, or other text manipulation tools.\n",
        "\n",
        "  4. Separate or Partial Freezing:\n",
        "    * freeze the classification head once it’s performing well and continue training the sentiment head (and maybe the backbone) a bit more to help the sentiment task catch up.\n",
        "\n",
        "  Note: you don’t want the larger dataset (Task A) to dominate over the other during the training. Balancing or re-weighing each task’s contribution ensures you don’t neglect the underrepresented task (Task B).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **(6) Additional self-made question: in early experiments that average loss is flucturing, what is concluded from that?**\n",
        "\n",
        "Examples of average loss using only 10 samples to train the task heads:\n",
        "```\n",
        "[Epoch 1/5] Average Loss: 2.2200\n",
        "[Epoch 2/5] Average Loss: 2.2187\n",
        "[Epoch 3/5] Average Loss: 2.2625\n",
        "[Epoch 4/5] Average Loss: 2.1628\n",
        "[Epoch 5/5] Average Loss: 2.1679\n",
        "Training complete!\n",
        "```\n",
        "Based on this observation, what is learned here:\n",
        "\n",
        "1. **The Loss is Fluctuating and Remains High**:\n",
        "  * The values hover around ~2.16–2.26 and do not show a clear, steady downward trend.For a cross-entropy loss across two tasks (classification + sentiment, each with 3 classes), you’d hope to see a loss eventually drop below ~1.8 or lower if the model is learning effectively. The fact that it stays around ~2.2 suggests limited or no meaningful learning on this dataset.\n",
        "\n",
        "2. **Very Small Dataset**:\n",
        "  * Using 10 samples, it’s extremely difficult to get stable losses or see a typical downward trend.\n",
        "  * The model can easily memorize the small training set but still produce high average loss if it cannot fit those few samples well or if tasks conflict.\n",
        "\n",
        "3. **Possible Over/Underfitting or Randomness**\n",
        "  * With so few samples, each individual batch heavily influences the average loss.\n",
        "  * Small changes in model weights can cause large swings in loss, especially with multi-task training.\n",
        "  * Also, if any parameters are still frozen or incorrectly set (e.g., if the backbone was not actually unfreezing), the model may barely move from random initialization.\n",
        "  * Model’s loss is not showing a clear downward trend and is staying around 2.2. This likely means it’s not learning effectively on such a small dataset.\n",
        "\n",
        "4. **Check the Training Configuration**\n",
        "  * Are you freezing or unfreezing the backbone? If you froze the backbone and only have 10 training samples for the new heads, the heads might not converge well.\n",
        "  * Learning rate: If it’s too high (e.g., 2e-5 for a tiny dataset) or too low.\n",
        "  * Batch size: With only 10 samples, and a batch size of 5, each epoch sees very few updates—any single example can skew the loss in a big way.\n",
        "\n",
        "**Improvements made based on the above observations:**\n",
        "\n",
        "  1. Gather more data: collected 200 sample datasets (100 short text with each less than 6 words, and 100 long text with each more than 6 words).\n",
        "  2. Lower the learning rate or experiment with different rates (e.g., 5e-6 is used later).\n",
        "\n",
        "#### What is learned from the new results of trained model:\n",
        "```\n",
        "Text: Your support team was very helpful\n",
        "Predicted Class: Service\n",
        "Predicted Sentiment: Positive\n",
        "\n",
        "Text: This new product is fantastic\n",
        "Predicted Class: Product\n",
        "Predicted Sentiment: Neutral\n",
        "\n",
        "Text: The product quality is outstanding!\n",
        "Predicted Class: Product\n",
        "Predicted Sentiment: Positive\n",
        "\n",
        "Text: Your customer service team was very helpful\n",
        "Predicted Class: Service\n",
        "Predicted Sentiment: Positive\n",
        "\n",
        "Text: I have some general feedback to share\n",
        "Predicted Class: General\n",
        "Predicted Sentiment: Positive\n",
        "\n",
        "Text: This product is completely useless\n",
        "Predicted Class: Product\n",
        "Predicted Sentiment: Neutral (**wrong!**)\n",
        "\n",
        "Text: The service was mediocre at best\n",
        "Predicted Class: Product (**wrong!**)\n",
        "Predicted Sentiment: Positive\n",
        "\n",
        "Text: I hate your horrible product\n",
        "Predicted Class: Product\n",
        "Predicted Sentiment: Positive (**wrong!**)\n",
        "```\n",
        "* Before the model was trained, the predicted class is all product, and the predicted sentiment is all positive.\n",
        "* After the model was trained, the model was able to capture the positive sentiment and classify more accurate than before. But it still failed to capture the negative sentiment here (marked as **wrong!** above).\n",
        "* In such case, **class imbalance** or **insufficient negative** examples is a main cause.\n",
        "\n"
      ],
      "metadata": {
        "id": "GhkbiG3qkduK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "sentiment_counts = Counter(sentiment_labels)\n",
        "print(sentiment_counts)  # e.g., {0: 30, 1: 100, 2: 70}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuKqn7x8qfpV",
        "outputId": "0002cd15-276b-4fdc-af51-9f43ae23e662"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 90, 1: 70, 0: 50})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label distribution `Counter({2: 90, 1: 70, 0: 50})` shows:\n",
        "```\n",
        "90 samples of label 2\n",
        "70 samples of label 1\n",
        "50 samples of label 0\n",
        "```\n",
        "So, positive class has 90 samples, neutral class has 70, and negative class has 50. While there is a difference in the counts, the imbalance is not extremely severe (for example, you don’t have one class with 5 samples and another with 100). However, it is somewhat imbalanced because the negative class has significantly fewer samples than the positive one (50 vs 90)."
      ],
      "metadata": {
        "id": "CFITvv56rN23"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7697b1b2-56ba-48d3-bf64-a68794a7d0ce",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Q9Pg7EyPd6ao"
      },
      "source": [
        "#### **(7) Finally, how to handle data imbalance based on the current anpve training and inference results?**\n",
        "\n",
        "1. **Data Collection & Balancing**\n",
        "  * Collect More Negative Samples: If negative examples are underrepresented, try to add more negative data (real user complaints, negative reviews, etc.).\n",
        "\n",
        "  * Data Augmentation: For underrepresented classes (e.g., negative), we can do text augmentation: paraphrasing, synonyms, changing sentence structure while keeping the negative sentiment. Tools like NLPAug or TextAttack (not used in this demo yet) can help generate variant sentences that maintain the same label.\n",
        "\n",
        "  * Stratified Sampling / Weighted Sampling: in DataLoader, we can weight classes inversely to their frequency so the model sees more negative samples during training.\n",
        "\n",
        "2. Class Weights or Focal Loss\n",
        "  * Class Weights in CrossEntropyLoss: use `torch.nn.CrossEntropyLoss(weight=...)` or a custom WeightedLoss, we can give higher weight to negative samples. This counters the model’s tendency to ignore rare classes.\n",
        "  * Focal Loss: Specifically designed to combat class imbalance by down-weighting easy examples and focusing more on hard, misclassified examples.\n",
        "\n",
        "3. Model Fine-Tuning Strategy\n",
        "  * Ensure Entire Backbone is Fine-Tuned (not implemented yet in this demo): If we only trained the heads, consider unfreezing the backbone once we have more data. This can significantly improve performance.\n",
        "\n",
        "  * Hyperparameter Tuning: Adjust learning rate, batch size, or number of epochs. With more data, we might do 3–5 epochs or more. Evaluate on a validation set after each epoch, consider early stopping or model checkpointing.\n",
        "\n",
        "  #### when training the multi-task models, assume that Task A (classification) has abundant data, while Task B (sentiment analysis) has limited data. Explain how you would handle this imbalance?\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "client": "2"
      },
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "experiments",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4a91c92d42a4eb18b340f560f85945b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd33d1dcf91d495792d8bf6c2abe9a8e",
              "IPY_MODEL_f324edbaa60c4ed2a96f40e85998b57b",
              "IPY_MODEL_b54fd13d273043f9aa8ef58657f13992"
            ],
            "layout": "IPY_MODEL_e1e991c6f1de440a86a49ef4e8f11763"
          }
        },
        "dd33d1dcf91d495792d8bf6c2abe9a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e5e587417d4ba49ba60eb7d4b77519",
            "placeholder": "​",
            "style": "IPY_MODEL_1e531e89c9354add817aac6a5bcb2b7c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f324edbaa60c4ed2a96f40e85998b57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a3458374cc4998a2ee880a70969a1e",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4523f57bfbd49529086d7d73d07c0d6",
            "value": 48
          }
        },
        "b54fd13d273043f9aa8ef58657f13992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9736a1df56a546128188c652637cc195",
            "placeholder": "​",
            "style": "IPY_MODEL_1c5e5ba6c8f04f0cbbd6a940fed3a195",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.05kB/s]"
          }
        },
        "e1e991c6f1de440a86a49ef4e8f11763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e5e587417d4ba49ba60eb7d4b77519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e531e89c9354add817aac6a5bcb2b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40a3458374cc4998a2ee880a70969a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4523f57bfbd49529086d7d73d07c0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9736a1df56a546128188c652637cc195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5e5ba6c8f04f0cbbd6a940fed3a195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59815f5f733340d78656ea6a2f02dd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee294420d32548adbd14ee1e3ac8291a",
              "IPY_MODEL_e2dacd37394b4412a6cfa7cddad3ae0c",
              "IPY_MODEL_87dfd7723a8d4e4e82f2a9464422ec0e"
            ],
            "layout": "IPY_MODEL_6028a2a3443b4fcaa0fb073c22b3fa66"
          }
        },
        "ee294420d32548adbd14ee1e3ac8291a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18387d2d6c274acda2ed5e8ba29b76e7",
            "placeholder": "​",
            "style": "IPY_MODEL_2a9ca2f3774844538d21bd706e4c8ed6",
            "value": "config.json: 100%"
          }
        },
        "e2dacd37394b4412a6cfa7cddad3ae0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b37b16980b414558b0349649b7c8926d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a9210b22cca434a9bed8c52fbf3264a",
            "value": 570
          }
        },
        "87dfd7723a8d4e4e82f2a9464422ec0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca359c971874001833f8622c8e1abf2",
            "placeholder": "​",
            "style": "IPY_MODEL_66f51e46fb6a43de9ea357f94a63ccef",
            "value": " 570/570 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "6028a2a3443b4fcaa0fb073c22b3fa66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18387d2d6c274acda2ed5e8ba29b76e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9ca2f3774844538d21bd706e4c8ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b37b16980b414558b0349649b7c8926d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9210b22cca434a9bed8c52fbf3264a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ca359c971874001833f8622c8e1abf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f51e46fb6a43de9ea357f94a63ccef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19aa18aa9d2940e9bed77e8e81c5c3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9f3ec5195654cffb8294dd87aa7bae9",
              "IPY_MODEL_a98146354acf42dba61184c7177d09ef",
              "IPY_MODEL_9214c0ded5cc4f32a129afd02daf2e10"
            ],
            "layout": "IPY_MODEL_d6cda59162ea4259a717fd1736821968"
          }
        },
        "b9f3ec5195654cffb8294dd87aa7bae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ffbbe5a41347a89294143d530cb9a5",
            "placeholder": "​",
            "style": "IPY_MODEL_15193d052f614bd1bb9877ff86ba65d2",
            "value": "vocab.txt: 100%"
          }
        },
        "a98146354acf42dba61184c7177d09ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3279bfab8e4f71835253f6bb82ddd7",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8686a316710b4b59ba5e26ac9992f0a1",
            "value": 231508
          }
        },
        "9214c0ded5cc4f32a129afd02daf2e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d668c80d1034709a367ffd832618475",
            "placeholder": "​",
            "style": "IPY_MODEL_2a47cd7af2ae4b289ae2056625d3c7bd",
            "value": " 232k/232k [00:00&lt;00:00, 4.52MB/s]"
          }
        },
        "d6cda59162ea4259a717fd1736821968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ffbbe5a41347a89294143d530cb9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15193d052f614bd1bb9877ff86ba65d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f3279bfab8e4f71835253f6bb82ddd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8686a316710b4b59ba5e26ac9992f0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d668c80d1034709a367ffd832618475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a47cd7af2ae4b289ae2056625d3c7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40b1f42dc9574bbc87bae51802d768bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_455500afe4c54d238073f953d57fc6a8",
              "IPY_MODEL_e191f19741ec472786cef82b8db3ee16",
              "IPY_MODEL_4c2e557b40894093be6d1b777deb1cc6"
            ],
            "layout": "IPY_MODEL_dfe2c9b7e2944758943485ef1e44cce7"
          }
        },
        "455500afe4c54d238073f953d57fc6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f3e77efb2d4017a447ea12a8b4a68f",
            "placeholder": "​",
            "style": "IPY_MODEL_a6b25d5d79004dd79e9ae42d0b3f040e",
            "value": "tokenizer.json: 100%"
          }
        },
        "e191f19741ec472786cef82b8db3ee16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4095583ec7c646289b854e36de933458",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74dd83868cab4783aec65ac381509706",
            "value": 466062
          }
        },
        "4c2e557b40894093be6d1b777deb1cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1a83cfffaa4e6a850ba7efa892737d",
            "placeholder": "​",
            "style": "IPY_MODEL_2dcd58ed520b4b88982892f587a7dd65",
            "value": " 466k/466k [00:00&lt;00:00, 17.9MB/s]"
          }
        },
        "dfe2c9b7e2944758943485ef1e44cce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f3e77efb2d4017a447ea12a8b4a68f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b25d5d79004dd79e9ae42d0b3f040e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4095583ec7c646289b854e36de933458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74dd83868cab4783aec65ac381509706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf1a83cfffaa4e6a850ba7efa892737d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcd58ed520b4b88982892f587a7dd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bcb8a3d4cb04095a4ebc9a1c3047810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c020f1d92fea40c78552ccb9856cac9d",
              "IPY_MODEL_cd85a79a093d4216882ed696d8e2b9d9",
              "IPY_MODEL_7ceaa997a69c4007a783cc0f10e482ce"
            ],
            "layout": "IPY_MODEL_c345dece3dc9495bb8f3a1d3edcf8924"
          }
        },
        "c020f1d92fea40c78552ccb9856cac9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c5e10500cd74799917057585da54f9a",
            "placeholder": "​",
            "style": "IPY_MODEL_6ebaac54ece04f948c11ce8d07c0913c",
            "value": "model.safetensors: 100%"
          }
        },
        "cd85a79a093d4216882ed696d8e2b9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff74c73b6d443dd9280d6d6f70557f8",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e99088fc65a4d7f8d447f68cf8a1904",
            "value": 440449768
          }
        },
        "7ceaa997a69c4007a783cc0f10e482ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_997629f1f66a4825baa850e39d2c309e",
            "placeholder": "​",
            "style": "IPY_MODEL_f2f2e3ae35584439896df5b4892a4917",
            "value": " 440M/440M [00:08&lt;00:00, 79.7MB/s]"
          }
        },
        "c345dece3dc9495bb8f3a1d3edcf8924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c5e10500cd74799917057585da54f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebaac54ece04f948c11ce8d07c0913c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bff74c73b6d443dd9280d6d6f70557f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e99088fc65a4d7f8d447f68cf8a1904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "997629f1f66a4825baa850e39d2c309e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f2e3ae35584439896df5b4892a4917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}